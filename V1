#!/usr/bin/env python
# coding: utf-8

# ייבוא הספריות הנדרשות
import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error

def prepare_data(df):
    """
    מבצעת עיבוד מוקדם והכנת הנתונים למודל.
    מקבלת DataFrame ומחזירה DataFrame מעובד עם השדות הרלוונטיים בלבד.
    """
    # בחירת השדות הרלוונטיים
    relevant_columns = ['manufactor', 'Year', 'model', 'Hand', 'Gear', 'Engine_capacity', 
                        'Engine_type', 'Prev_ownership', 'Curr_ownership', 'Price', 
                        'Pic_num', 'Cre_date', 'Repub_date', 'Km', 'Test']
    df = df[relevant_columns]
    
    # טיפול בערכים חסרים
    numeric_columns = ['Year', 'Hand', 'Engine_capacity', 'Pic_num', 'Km', 'Test']
    categorical_columns = ['manufactor', 'model', 'Gear', 'Engine_type', 'Prev_ownership', 'Curr_ownership']
    
    # שימוש ב-SimpleImputer עבור עמודות מספריות
    numeric_imputer = SimpleImputer(strategy='median')
    df[numeric_columns] = numeric_imputer.fit_transform(df[numeric_columns])
    
    # שימוש ב-SimpleImputer עבור עמודות קטגוריות
    categorical_imputer = SimpleImputer(strategy='most_frequent')
    df[categorical_columns] = categorical_imputer.fit_transform(df[categorical_columns])
    
    # המרת תאריכים למספר ימים
    df['Cre_days'] = (pd.to_datetime('today') - pd.to_datetime(df['Cre_date'])).dt.days
    df['Repub_days'] = (pd.to_datetime('today') - pd.to_datetime(df['Repub_date'])).dt.days
    
    # הסרת עמודות התאריך המקוריות
    df = df.drop(['Cre_date', 'Repub_date'], axis=1)
    
    # Feature engineering: יצירת מאפיין חדש 'age'
    df['age'] = pd.to_datetime('today').year - df['Year']
    
    return df

# קריאת הנתונים
df = pd.read_csv('dataset.csv')

# הכנת הנתונים
X = prepare_data(df)
y = X.pop('Price')  # הפרדת המשתנה התלוי

# חלוקה ל-train ו-test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# הגדרת המאפיינים המספריים והקטגוריים
numeric_features = ['Year', 'Hand', 'Engine_capacity', 'Pic_num', 'Km', 'Test', 'Cre_days', 'Repub_days', 'age']
categorical_features = ['manufactor', 'model', 'Gear', 'Engine_type', 'Prev_ownership', 'Curr_ownership']

# יצירת ColumnTransformer לטיפול במאפיינים מספריים וקטגוריים
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)
    ])

# יצירת הפייפליין
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', ElasticNet(random_state=42))
])

# הגדרת הפרמטרים לחיפוש
param_grid = {
    'model__alpha': [0.1, 1, 10],
    'model__l1_ratio': [0.1, 0.5, 0.9]
}

# ביצוע Grid Search עם Cross-Validation
grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# הדפסת התוצאות הטובות ביותר
print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score (RMSE):", np.sqrt(-grid_search.best_score_))

# זיהוי המאפיינים המשפיעים ביותר
best_model = grid_search.best_estimator_
feature_names = (numeric_features + 
                 [f"{feature}_{val}" for feature, vals in 
                  zip(categorical_features, best_model.named_steps['preprocessor']
                      .named_transformers_['cat'].categories_) 
                  for val in vals])
feature_importance = pd.DataFrame({'feature': feature_names, 
                                   'importance': abs(best_model.named_steps['model'].coef_)})
feature_importance = feature_importance.sort_values('importance', ascending=False)
print("\nTop 5 most important features:")
print(feature_importance.head())

# הערכת המודל הסופי עם Cross-Validation
cv_scores = cross_val_score(best_model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)
print("\nCross-validation RMSE scores:", rmse_scores)
print("Mean RMSE:", rmse_scores.mean())
print("Standard deviation of RMSE:", rmse_scores.std())

# חיזוי על סט הבדיקה
y_pred = best_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("\nTest set RMSE:", test_rmse)
